---
title: "Cyclistic"
author: "Amine Ouadid"
date: "2023-11-17"
output: html_document
---
---
title: "Cyclistic Divvy Bikes Case Study"
author: "Amine Ouadid"
date: "2023-11-17"
output: html_document
---

## Introduction:

Here is my case study on a cyclic analysis of bike sharing. Here, we'll discuss actual issues that Chicago-based bike-share Company named Cyclistic has to deal with. 
We will use the data analysis method to provide actionable insights and address important business problems during this investigation.

### Deliverables:

According to Lily Moreno, head of marketing for the company, increasing the number of yearly subscriptions is critical to Cyclistic's success going forward. To do this, we want to comprehend how casual riders and annual members behave differently from one another and use that knowledge to inform the creation of a fresh marketing plan. We have to:

1. Get a thorough grasp of the unique actions and inclinations that casual riders and annual members display.
2.Develop an innovative and targeted marketing strategy that effectively converts casual riders into loyal annual members.
3. Provide attractive data insights and expert data visualizations to back up our thesis and marketing recommendations.

## Problem:

Three questions will guide the future marketing program:

1. How do annual members and casual riders use Cyclistic bikes differently?

2. Why would casual riders buy Cyclistic annual memberships?

3. How can Cyclistic use digital media to influence casual riders to become members?

Moreno has assigned us the first question to answer: How do annual members and casual riders use Cyclistic bikes differently?
The rest are handled by other team members.

### Ask:

We will produce a report with the following deliverables:

1. A clear statement of the business task:

Our main objectives are to increase the number of casual cyclists who become committed yearly members, cultivate enduring loyalty, and accelerate Cyclistic's expansion.

2. A description of all data sources used:

We will use Cyclisticâ€™s historical trip data to analyze and identify trends. Our analysis will be based on the last annual cycle. 
for 2019_Q2 2019_Q3 2019_Q4 and 2020_Q1. The data has been made available by Motivate International Inc. under this [License](https://ride.divvybikes.com/data-license-agreement).

3. Documentation of any cleaning or manipulation of data:

All Excel and R cleaning and manipulation are found in this portfolio.

4. A summary of your analysis:

Members have a 54% higher riding frequency annually compared to casual users. The most popular days for members are Tuesday through Thursday, which is consistent with the assumption that people primarily use the bikes for weekday journeys to work. 
The peak riding hours for both regular users and members are from 3 to 6 p.m., suggesting that this is a highly sought-after time slot. 
While casual users favor Lake Shore and Streeter Dr., members' preferred start and end locations are Canal & Adams and Clinton Street. 
Saturday and Sunday are the days that casual users ride the most, suggesting that they favor the weekends.
Compared to members, casual users average 59% longer rides, which may suggest a desire for longer rides or exploring new places.

5. Supporting visualizations and key findings:

All Excel and R supporting visualizations are found in this portfolio.

6. Your top three recommendations based on your analysis

1. Put your attention on focused marketing that lowers costs while enhancing marketing outcomes by promoting membership perks and offering exclusive discounts where casual users are most likely to congregate. 
  
2. Provide incentives, such as lower carbon footprints, financial savings, and longer health spans from low-impact physical activity, to entice casual riders to switch.
  
3. Use data-driven user type hotspots to create tailored surveys that all user types can respond to in order to obtain further insight.

## Solution:

As it happens, the answer lies outside the purview of our task. Without responding to the other two stakeholder questions, any consequences are merely conjecture. You can learn specifics about the distinctions between causal riders and annual members, though, by answering our question. 
Having said that, for this four-quarter period:

* Members ride 54% more often than casual users
* Members most often ride from Tuesday to Thursday and weekdays in general
* Members top start and end stations are located at Canal & Adams and Clinton Street.
* Casual users top start and end stations are located at Lake Shore and Streeter Dr.
* Casual users most often ride on Saturdays and weekends in general
* Casual users ride 59% longer than members on average
* Casual users prefer the weekends, while members prefer the weekdays
* Both members and casual users most often ride between 3-6 p.m

## Next steps:

We ought to work together with the other members of the team and compile their insights from the questions Lily Moreno gave them. 

Then, I would advise that we think about implementing targeted advertising in their most popular sites and offering discounts aimed at casual customers. 

I would advise collecting more information from every user by making surveys for every kind that they receive through email or following a purchase.



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Check and set working directory to simplify calls to data
```{r Check and set working directory to simplify calls to data}
getwd()
setwd("C:/Users/Dell/Desktop/divvy_bike_data/divvy_bike_data")
```
# Install required packages
```{r Install required packages}
options(repos = structure(c(CRAN = "https://cran.r-project.org")))
install.packages("tidyverse")
install.packages("lubridate")
install.packages("ggplot2")
library(tidyverse)  #helps wrangle data
library(lubridate)  #helps wrangle date attributes
library(ggplot2)  #helps visualize data
```
#======================
#STEP 1: COLLECT DATA
#======================
# Collect data, upload Divvy dataset
```{r Upload .csv files}
q4_2019 <- read_csv("Divvy_Trips_2019_Q4.csv")
q3_2019 <- read_csv("Divvy_Trips_2019_Q3.csv")
q2_2019 <- read_csv("Divvy_Trips_2019_Q2.csv")
q1_2020 <- read_csv("Divvy_Trips_2020_Q1.csv")
```
#====================================================
#STEP 2: WRANGLE DATA AND COMBINE INTO A SINGLE FILE
#====================================================
# Compare column names in each of the files
```{r Compare column names}
colnames(q4_2019)
colnames(q3_2019)
colnames(q2_2019)
colnames(q1_2020)
```
# Rename columns  to make them consisent with q1_2020
```{r Clean up column names}
(q2_2019 <- rename(q2_2019
                   ,ride_id = "01 - Rental Details Rental ID"
                   ,rideable_type = "01 - Rental Details Bike ID" 
                   ,started_at = "01 - Rental Details Local Start Time"  
                   ,ended_at = "01 - Rental Details Local End Time"  
                   ,start_station_name = "03 - Rental Start Station Name" 
                   ,start_station_id = "03 - Rental Start Station ID"
                   ,end_station_name = "02 - Rental End Station Name" 
                   ,end_station_id = "02 - Rental End Station ID"
                   ,member_casual = "User Type"))

(q3_2019 <- rename(q3_2019
                   ,ride_id = "trip_id"
                   ,rideable_type = "bikeid" 
                   ,started_at = "start_time"  
                   ,ended_at = "end_time"  
                   ,start_station_name = "from_station_name" 
                   ,start_station_id = "from_station_id" 
                   ,end_station_name = "to_station_name" 
                   ,end_station_id = "to_station_id" 
                   ,member_casual = "usertype"))

(q4_2019 <- rename(q4_2019
                   ,ride_id = "trip_id"
                   ,rideable_type = "bikeid" 
                   ,started_at = "start_time"  
                   ,ended_at = "end_time"  
                   ,start_station_name = "from_station_name" 
                   ,start_station_id = "from_station_id" 
                   ,end_station_name = "to_station_name" 
                   ,end_station_id = "to_station_id" 
                   ,member_casual = "usertype"))
```
# Inspect the data frames and look for incongruencies
```{r check out the struckture of each data set}
str(q1_2020)
str(q4_2019)
str(q2_2019)
str(q3_2019)
```
# Convert ride_id and rideable_type to character so that they can stack correctly
```{r}
q4_2019 <-  mutate(q4_2019, ride_id = as.character(ride_id),rideable_type = as.character(rideable_type)) 
q3_2019 <-  mutate(q3_2019, ride_id = as.character(ride_id),rideable_type = as.character(rideable_type))
q2_2019 <-  mutate(q2_2019, ride_id = as.character(ride_id),rideable_type = as.character(rideable_type))
```
# Stack individual quarter's data frames into one big data frame
```{r Aggregate data}
all_trips <- bind_rows(q2_2019, q3_2019, q4_2019, q1_2020)
```
# Remove lat, long, birthyear, and gender fields as this data was dropped beginning in 2020
```{r Remove irrelevant data}
all_trips <- all_trips %>% 
  select(-c(start_lat, start_lng, end_lat, end_lng, birthyear, gender, "01 - Rental Details Duration In Seconds Uncapped", "05 - Member Details Member Birthday Year", "Member Gender","tripduration"))
```
#=====================================================
#STEP 3: CLEAN UP AND ADD DATA TO PREPARE FOR ANALYSIS
#=====================================================
# Inspect the new table that has been created
```{r Inspect new table}
colnames(all_trips)  #List of column names

nrow(all_trips)  #How many rows are in data frame?

dim(all_trips)  #Dimensions of the data frame?

head(all_trips)  #See the first 6 rows of data frame.  Also tail(qs_raw)

str(all_trips)  #See list of columns and data types (numeric, character, etc)

summary(all_trips)  #Statistical summary of data. Mainly for numerics
```
### There are a few problems we will need to fix:
### (1) In the "member_casual" column, there are two names for members ("member" and "Subscriber") and two names for casual riders ("Customer" and "casual"). We will need to consolidate that from four to two labels.
### (2) The data can only be aggregated at the ride-level, which is too granular. We will want to add some additional columns of data -- such as day, month, year -- that provide additional opportunities to aggregate the data.
### (3) We will want to add a calculated field for length of ride since the 2020Q1 data did not have the "tripduration" column. We will add "ride_length" to the entire dataframe for consistency.
### (4) There are some rides where tripduration shows up as negative, including several hundred rides where Divvy took bikes out of circulation for Quality Control reasons. We will want to delete these rides.

# Begin by seeing how many observations fall under each usertype
```{r}
table(all_trips$member_casual)
```
# Reassign to the desired values (we will go with the current 2020 labels)
```{r}
all_trips <-  all_trips %>% 
  mutate(member_casual = recode(member_casual
                                ,"Subscriber" = "member"
                                ,"Customer" = "casual"))
```
# Check to make sure the proper number of observations were reassigned
```{r Inspect data to ensure numbers match}
table(all_trips$member_casual)
```
# Add columns that list the date, month, day, and year of each ride
# This will allow us to aggregate ride data for each month, day, or year ... before completing these operations we could only aggregate at the ride level
```{r}
all_trips$date <- as.Date(all_trips$started_at) #The default format is yyyy-mm-dd
all_trips$month <- format(as.Date(all_trips$date), "%m")
all_trips$day <- format(as.Date(all_trips$date), "%d")
all_trips$year <- format(as.Date(all_trips$date), "%Y")
all_trips$day_of_week <- format(as.Date(all_trips$date), "%A")
```
# Add a "ride_length" calculation to all_trips (in seconds)
```{r Add ride length column}
all_trips$ride_length <- difftime(all_trips$ended_at,all_trips$started_at)
```
# Inspect the structure of the columns
```{r}
str(all_trips)
```
# Convert "ride_length" from Factor to numeric so we can run calculations on the data
```{r}
is.factor(all_trips$ride_length)
all_trips$ride_length <- as.numeric(as.character(all_trips$ride_length))
is.numeric(all_trips$ride_length)
```
##Remove "bad" data

# The dataframe includes a few hundred entries when bikes were taken out of docks and checked for quality by Divvy or ride_length was negative
# We will create a new version of the dataframe (v2) since data is being removed
```{r}
all_trips_v2 <- all_trips[!(all_trips$start_station_name == "HQ QR" | all_trips$ride_length<0),]
```

#=====================================
# STEP 4: CONDUCT DESCRIPTIVE ANALYSIS
#=====================================
# Descriptive analysis on ride_length (all figures in seconds)
```{r}
mean(all_trips_v2$ride_length) #straight average (total ride length / rides)
median(all_trips_v2$ride_length) #midpoint number in the ascending array of ride lengths
max(all_trips_v2$ride_length) #longest ride
min(all_trips_v2$ride_length) #shortest ride
```

# condense the four lines above to one line using summary() on the specific attribute
```{r}
summary(all_trips_v2$ride_length)
```
# Compare members and casual users
```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = mean)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = median)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = max)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = min)
```
# See the average ride time by each day for members vs casual users
```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
```
# Notice that the days of the week are out of order. Let's fix that.
```{r}
all_trips_v2$day_of_week <- ordered(all_trips_v2$day_of_week, levels=c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))
```
# Now, let's run the average ride time by each day for members vs casual users
```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
```
# analyze ridership data by type and weekday
```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>%  #creates weekday field using wday()
  group_by(member_casual, weekday) %>%  #groups by usertype and weekday
  summarise(number_of_rides = n()							#calculates the number of rides and average duration 
            ,average_duration = mean(ride_length)) %>% 		# calculates the average duration
  arrange(member_casual, weekday)								# sorts
```
# Let's visualize the number of rides by rider type
```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = number_of_rides, fill = member_casual)) +
  geom_col(position = "dodge")
```
# Let's create a visualization for average duration
```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = average_duration, fill = member_casual)) +
  geom_col(position = "dodge")
```

#=================================================
# STEP 5: EXPORT SUMMARY FILE FOR FURTHER ANALYSIS
#=================================================

# Create a csv file that we will visualize in Excel, Tableau, or my presentation software
```{r}
counts <- aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
write.csv(counts, file = 'C:\\Users\\Dell\\Desktop\\divvy_bike_data\\avg_ride_length.csv')
```
